WEBVTT

1
00:00:04.260 --> 00:00:08.640
Welcome to an introduction
to Amazon SageMaker Neo.

2
00:00:08.640 --> 00:00:11.260
Hello, my name is
Michelle Metzger and I'm

3
00:00:11.260 --> 00:00:13.000
a technical curriculum
developer in

4
00:00:13.000 --> 00:00:16.165
the Training and Certification
organization of AWS.

5
00:00:16.165 --> 00:00:18.940
In this video, I'll start
by explaining some of

6
00:00:18.940 --> 00:00:20.470
the challenges that
our customers are

7
00:00:20.470 --> 00:00:22.810
facing when performing
Machine Learning.

8
00:00:22.810 --> 00:00:26.395
Then, introduce you to what
Amazon SageMaker Neo is,

9
00:00:26.395 --> 00:00:28.060
and some of its benefits.

10
00:00:28.060 --> 00:00:30.205
I'll walk through a
couple of use cases

11
00:00:30.205 --> 00:00:32.830
and wrap up with
some key takeaways.

12
00:00:32.830 --> 00:00:35.110
First, let's begin by covering

13
00:00:35.110 --> 00:00:37.630
the concepts and challenges
of Machine Learning,

14
00:00:37.630 --> 00:00:41.210
and how Amazon SageMaker Neo
addresses some of these.

15
00:00:41.210 --> 00:00:44.140
Nowadays, Machine
Learning is universally

16
00:00:44.140 --> 00:00:47.395
used by customers to make
informed business decisions.

17
00:00:47.395 --> 00:00:49.300
Developers who want to use

18
00:00:49.300 --> 00:00:52.775
Machine Learning encounter
hurdles at every step.

19
00:00:52.775 --> 00:00:54.520
First, they need to choose

20
00:00:54.520 --> 00:00:57.340
a framework that's best-suited
for the task at hands.

21
00:00:57.340 --> 00:00:59.170
Second, they need to build

22
00:00:59.170 --> 00:01:01.510
models using their
chosen framework.

23
00:01:01.510 --> 00:01:04.240
Third, they need to
train a model using

24
00:01:04.240 --> 00:01:05.545
sample data to make

25
00:01:05.545 --> 00:01:07.995
accurate predictions
on their data sets.

26
00:01:07.995 --> 00:01:09.940
Forth, they need to

27
00:01:09.940 --> 00:01:12.855
integrate their model
with their application.

28
00:01:12.855 --> 00:01:15.855
Finally, they need to
deploy the application,

29
00:01:15.855 --> 00:01:19.625
the model, and the
framework on a platform.

30
00:01:19.625 --> 00:01:22.560
Amazon SageMaker Neo
makes it easy to

31
00:01:22.560 --> 00:01:25.000
build Machine Learning
models and get them

32
00:01:25.000 --> 00:01:27.340
ready for training by
providing everything you

33
00:01:27.340 --> 00:01:30.140
need to quickly connect
to your training data.

34
00:01:30.140 --> 00:01:32.810
It also helps you to
select and optimize

35
00:01:32.810 --> 00:01:36.545
the best algorithm and
framework for your application.

36
00:01:36.545 --> 00:01:39.230
However, developers still face

37
00:01:39.230 --> 00:01:41.150
hundreds of hurdles
when they try to

38
00:01:41.150 --> 00:01:42.455
deploy a model with

39
00:01:42.455 --> 00:01:46.220
optimal performance on
multiple platforms.

40
00:01:46.220 --> 00:01:48.380
Let's review a few details about

41
00:01:48.380 --> 00:01:50.840
the realities of
model deployment.

42
00:01:50.840 --> 00:01:53.090
To begin with, developers need

43
00:01:53.090 --> 00:01:55.010
to have the specific version of

44
00:01:55.010 --> 00:01:57.125
the framework used for
building the models

45
00:01:57.125 --> 00:01:59.630
installed on all of
their chosen platforms.

46
00:01:59.630 --> 00:02:03.020
However, platform vendors
often limits support to

47
00:02:03.020 --> 00:02:05.510
just one or two frameworks
because of the cost and

48
00:02:05.510 --> 00:02:08.840
complexity of optimizing and
installing those frameworks.

49
00:02:08.840 --> 00:02:12.125
Not to mention the size of
the frameworks themselves,

50
00:02:12.125 --> 00:02:13.430
which limit the type of

51
00:02:13.430 --> 00:02:15.625
platform on which it
can be installed.

52
00:02:15.625 --> 00:02:17.580
To work around these limitations,

53
00:02:17.580 --> 00:02:20.210
developers either restrict
the model deployment

54
00:02:20.210 --> 00:02:22.445
to fewer platforms or worse,

55
00:02:22.445 --> 00:02:25.595
use a framework that can
run on more platforms even

56
00:02:25.595 --> 00:02:27.650
if it's not the
best-suited framework

57
00:02:27.650 --> 00:02:29.090
for the task at hand.

58
00:02:29.090 --> 00:02:32.060
In this situation,
developers must manually

59
00:02:32.060 --> 00:02:35.210
tune the performance of their
models on each platform,

60
00:02:35.210 --> 00:02:36.920
which requires rare skills and

61
00:02:36.920 --> 00:02:39.350
consumes a considerable
amount of time.

62
00:02:39.350 --> 00:02:41.930
As a result, developers
often have to

63
00:02:41.930 --> 00:02:44.780
settle for sub-optimal
performance in their models.

64
00:02:44.780 --> 00:02:46.760
This sub-optimal performance

65
00:02:46.760 --> 00:02:49.084
underutilizes the
platform resources,

66
00:02:49.084 --> 00:02:50.960
which increases the overall cost

67
00:02:50.960 --> 00:02:52.315
of the model's deployment.

68
00:02:52.315 --> 00:02:55.009
Ultimately, these
hurdles restrict

69
00:02:55.009 --> 00:02:57.845
the diffusion of innovations
in Machine Learning.

70
00:02:57.845 --> 00:02:59.780
Developers find themselves in

71
00:02:59.780 --> 00:03:02.240
a situation requiring
their solutions

72
00:03:02.240 --> 00:03:06.320
to run on multiple platforms
using multiple frameworks.

73
00:03:06.320 --> 00:03:09.380
A machine learning framework
provides functions and

74
00:03:09.380 --> 00:03:11.540
operations that developers use

75
00:03:11.540 --> 00:03:13.835
as building blocks
for their models.

76
00:03:13.835 --> 00:03:15.680
These functions and operations

77
00:03:15.680 --> 00:03:17.735
differ from framework
to framework.

78
00:03:17.735 --> 00:03:21.140
Also, each framework has
its own mechanism to save

79
00:03:21.140 --> 00:03:24.740
the models and often has
unique file formats.

80
00:03:24.740 --> 00:03:28.250
At runtime, the framework
reads the model to generate

81
00:03:28.250 --> 00:03:32.150
the code and runs that code
on each unique platform.

82
00:03:32.150 --> 00:03:34.640
This means, that the
model can only run on

83
00:03:34.640 --> 00:03:38.365
the framework on the platform
in which it was built,

84
00:03:38.365 --> 00:03:40.805
and only on the
hardware configuration

85
00:03:40.805 --> 00:03:42.980
on which the framework
is supported.

86
00:03:42.980 --> 00:03:44.840
Do you see the problem here?

87
00:03:44.840 --> 00:03:47.960
It is painful to have
all of the platforms,

88
00:03:47.960 --> 00:03:51.185
support all of the models
from all of the frameworks.

89
00:03:51.185 --> 00:03:53.450
This solution is super messy,

90
00:03:53.450 --> 00:03:55.220
just like you see here.

91
00:03:55.220 --> 00:03:57.920
Amazon SageMaker
Neo is designed to

92
00:03:57.920 --> 00:04:00.575
solve the messy problem
I just showed you.

93
00:04:00.575 --> 00:04:02.600
It frees a model from

94
00:04:02.600 --> 00:04:04.580
the framework in which
it was developed

95
00:04:04.580 --> 00:04:06.560
and allows it to
make the best use

96
00:04:06.560 --> 00:04:09.055
of the hardware on
which it was deployed.

97
00:04:09.055 --> 00:04:11.900
Now, let's take a look
at how Neo works,

98
00:04:11.900 --> 00:04:14.240
and review some of its benefits.

99
00:04:14.240 --> 00:04:18.170
Amazon SageMaker Neo is a
new SageMaker capability

100
00:04:18.170 --> 00:04:19.610
that helps developers take

101
00:04:19.610 --> 00:04:21.890
models trained in any framework,

102
00:04:21.890 --> 00:04:24.500
and port them on to
any platform while

103
00:04:24.500 --> 00:04:25.910
increasing their performance

104
00:04:25.910 --> 00:04:28.450
and reducing their footprints.

105
00:04:28.450 --> 00:04:31.070
Neo provides model portability by

106
00:04:31.070 --> 00:04:34.280
converting models
written in Apache MXNet,

107
00:04:34.280 --> 00:04:37.955
PyTorch, TensorFlow, and XGBoost,

108
00:04:37.955 --> 00:04:42.220
from a framework specific
formats into a portable code.

109
00:04:42.220 --> 00:04:43.785
During conversion,

110
00:04:43.785 --> 00:04:46.640
Neo automatically
optimizes the model to run

111
00:04:46.640 --> 00:04:48.500
up to two times faster

112
00:04:48.500 --> 00:04:51.140
without a noticeable
loss in accuracy.

113
00:04:51.140 --> 00:04:53.160
After conversion, the model

114
00:04:53.160 --> 00:04:55.120
no longer needs the framework,

115
00:04:55.120 --> 00:04:57.560
which reduces its
runtime footprint on

116
00:04:57.560 --> 00:05:00.830
the development platform
by a 100 times.

117
00:05:00.830 --> 00:05:04.444
Customers can access Neo
from the SageMaker console,

118
00:05:04.444 --> 00:05:05.900
and with just a few clicks,

119
00:05:05.900 --> 00:05:09.440
generate a model optimized
for their specific platform.

120
00:05:09.440 --> 00:05:12.245
Neo contains two components;

121
00:05:12.245 --> 00:05:15.145
a compiler, and a
runtime library.

122
00:05:15.145 --> 00:05:17.750
First, the Neo compiler reads

123
00:05:17.750 --> 00:05:20.630
models saved in various formats.

124
00:05:20.630 --> 00:05:22.770
Those formats used framework

125
00:05:22.770 --> 00:05:24.940
specific functions
and operations.

126
00:05:24.940 --> 00:05:28.625
Neo converts those specific
functions and operations,

127
00:05:28.625 --> 00:05:31.565
into non-specific
functions and operations,

128
00:05:31.565 --> 00:05:34.865
often called Framework
Agnostic Representations.

129
00:05:34.865 --> 00:05:39.775
Next, Neo will perform a
series of optimizations.

130
00:05:39.775 --> 00:05:42.215
Now here's a
high-level explanation

131
00:05:42.215 --> 00:05:44.150
of how Neo could work.

132
00:05:44.150 --> 00:05:46.220
First, the user submits

133
00:05:46.220 --> 00:05:49.100
the compilation job requests
to Amazon SageMaker,

134
00:05:49.100 --> 00:05:51.590
and the job status is
changed to starting.

135
00:05:51.590 --> 00:05:53.010
After a few moments,

136
00:05:53.010 --> 00:05:56.125
the job status will
change to, in-progress.

137
00:05:56.125 --> 00:05:57.770
This is when the process of

138
00:05:57.770 --> 00:05:59.944
compiling the model
really begins,

139
00:05:59.944 --> 00:06:02.185
this process can take a while.

140
00:06:02.185 --> 00:06:03.620
Now, during this time,

141
00:06:03.620 --> 00:06:05.900
the user has the ability to stop

142
00:06:05.900 --> 00:06:08.690
the job if they need
to for any reason.

143
00:06:08.690 --> 00:06:10.530
When the user stops the job,

144
00:06:10.530 --> 00:06:13.120
the status will be
changed to stopping,

145
00:06:13.120 --> 00:06:15.170
Amazon ECS will then begin

146
00:06:15.170 --> 00:06:17.390
the process of stopping
the compilation.

147
00:06:17.390 --> 00:06:19.175
Once that is completed,

148
00:06:19.175 --> 00:06:22.235
the job status will then
be changed to stop.

149
00:06:22.235 --> 00:06:23.660
Now in most cases,

150
00:06:23.660 --> 00:06:25.070
the user is not going
to want to stop

151
00:06:25.070 --> 00:06:26.750
the job right in the middle,

152
00:06:26.750 --> 00:06:28.460
Amazon ECS will then be

153
00:06:28.460 --> 00:06:31.085
allowed to complete
the compilation.

154
00:06:31.085 --> 00:06:32.780
Once this is completed,

155
00:06:32.780 --> 00:06:35.960
the job status will then
be changed to complete.

156
00:06:35.960 --> 00:06:40.085
So what are the benefits
of SageMaker Neo?

157
00:06:40.085 --> 00:06:41.630
Well, earlier I mentioned

158
00:06:41.630 --> 00:06:43.400
the burdens that developers carry

159
00:06:43.400 --> 00:06:44.600
when it comes to developing

160
00:06:44.600 --> 00:06:46.910
Agnostic Machine Learning models.

161
00:06:46.910 --> 00:06:48.230
The prior lack of

162
00:06:48.230 --> 00:06:50.630
simple-to-use profilers
and compilers and

163
00:06:50.630 --> 00:06:52.790
Machine Learning had
forced developers

164
00:06:52.790 --> 00:06:55.280
into a manual trial
and error process,

165
00:06:55.280 --> 00:06:58.760
that is unreliable and
quite frankly unproductive.

166
00:06:58.760 --> 00:07:01.570
Enter Amazon SageMaker Neo.

167
00:07:01.570 --> 00:07:03.470
Amazon sage Maker Neo provides

168
00:07:03.470 --> 00:07:05.480
developers with a simple easy to

169
00:07:05.480 --> 00:07:06.800
use tool to perform

170
00:07:06.800 --> 00:07:09.185
the conversion of
framework specific models,

171
00:07:09.185 --> 00:07:11.530
and port them to any platform.

172
00:07:11.530 --> 00:07:14.150
Neo automatically
optimizes the model

173
00:07:14.150 --> 00:07:16.130
to run up to two times faster,

174
00:07:16.130 --> 00:07:18.710
without a noticeable
loss in accuracy.

175
00:07:18.710 --> 00:07:20.360
To optimize the model,

176
00:07:20.360 --> 00:07:23.735
Neo detects and exploits
patterns in the input data,

177
00:07:23.735 --> 00:07:26.980
model computation, and
platform hardware.

178
00:07:26.980 --> 00:07:29.060
After conversion, the model

179
00:07:29.060 --> 00:07:31.100
can run without
needing any framework,

180
00:07:31.100 --> 00:07:34.550
which dramatically reduces the
model's runtime footprint.

181
00:07:34.550 --> 00:07:37.760
This allows the model to run
in resource constrained,

182
00:07:37.760 --> 00:07:42.055
edge devices, and
performance-critical Cloud services.

183
00:07:42.055 --> 00:07:44.615
Let's take a look at
a possible use case

184
00:07:44.615 --> 00:07:46.265
for a SageMaker Neo.

185
00:07:46.265 --> 00:07:48.590
Neo enables and accelerates

186
00:07:48.590 --> 00:07:50.360
Machine Learning models both in

187
00:07:50.360 --> 00:07:52.495
the Cloud and at the Edge.

188
00:07:52.495 --> 00:07:54.840
For mobile phone and IoT devices,

189
00:07:54.840 --> 00:07:56.460
Neo can help developers

190
00:07:56.460 --> 00:07:58.770
better deploy image
classification,

191
00:07:58.770 --> 00:08:01.380
object detection, and
anomaly detection

192
00:08:01.380 --> 00:08:03.320
applications by relaxing

193
00:08:03.320 --> 00:08:05.930
multiple constraints
on those devices.

194
00:08:05.930 --> 00:08:08.840
In the Cloud, Neo
compiles models to

195
00:08:08.840 --> 00:08:11.795
handle data stored in
Amazon S3 buckets,

196
00:08:11.795 --> 00:08:13.730
or coming in as data streams.

197
00:08:13.730 --> 00:08:16.235
Neo also enables new use cases,

198
00:08:16.235 --> 00:08:17.450
such as the integration of

199
00:08:17.450 --> 00:08:19.555
Machine Learning with databases.

200
00:08:19.555 --> 00:08:21.380
Developers will be able to take

201
00:08:21.380 --> 00:08:23.810
Machine Learning
models produced by Neo

202
00:08:23.810 --> 00:08:25.460
and run them in databases in

203
00:08:25.460 --> 00:08:28.055
the form of
user-defined functions.

204
00:08:28.055 --> 00:08:29.810
These models will enable

205
00:08:29.810 --> 00:08:32.480
complex predictive queries
that are currently

206
00:08:32.480 --> 00:08:34.370
impossible or unwieldy to

207
00:08:34.370 --> 00:08:37.625
express in ANSI
standard SQL language.

208
00:08:37.625 --> 00:08:40.890
So what are the key
takeaways from this video?

209
00:08:40.890 --> 00:08:42.620
Well, SageMaker Neo supports

210
00:08:42.620 --> 00:08:44.840
the most popular deep
learning models,

211
00:08:44.840 --> 00:08:46.190
that power computer vision

212
00:08:46.190 --> 00:08:49.610
applications and the most
popular decision tree

213
00:08:49.610 --> 00:08:51.170
models currently used in

214
00:08:51.170 --> 00:08:54.080
Amazon SageMaker. Neo optimizes

215
00:08:54.080 --> 00:08:56.150
the performance of AlexNet,

216
00:08:56.150 --> 00:09:00.635
ResNet, VGG,
Inception, MobileNet,

217
00:09:00.635 --> 00:09:03.170
SqueezeNet, and DenseNet models,

218
00:09:03.170 --> 00:09:07.325
trained in MXNet, TensorFlow,
and even PyTorch.

219
00:09:07.325 --> 00:09:10.655
It also optimizes the
performance of classification

220
00:09:10.655 --> 00:09:14.380
and Random Cut Forest
models trained in XGBoosts.

221
00:09:14.380 --> 00:09:16.290
Neo supports many different

222
00:09:16.290 --> 00:09:18.545
SageMaker instance types as well.

223
00:09:18.545 --> 00:09:20.960
It supports AWS DeepLens,

224
00:09:20.960 --> 00:09:25.190
Raspberry Pi, Jetson
TX1 or TX2 devices,

225
00:09:25.190 --> 00:09:29.015
Amazon Greengrass devices,
based on Intel processors,

226
00:09:29.015 --> 00:09:32.240
as well as in video
Maxwell and Pascal GPUs.

227
00:09:32.240 --> 00:09:34.770
Developers can train
models elsewhere,

228
00:09:34.770 --> 00:09:38.925
and use Neo to optimize them
for SageMaker ML instances,

229
00:09:38.925 --> 00:09:41.655
or Greengrass supported devices.

230
00:09:41.655 --> 00:09:44.790
Neo provides model
inference modules,

231
00:09:44.790 --> 00:09:47.190
which can run up to
two times faster,

232
00:09:47.190 --> 00:09:50.690
while occupying a dramatically
reduced memory footprint,

233
00:09:50.690 --> 00:09:53.000
versus previous solutions.

234
00:09:53.000 --> 00:09:55.550
You can use the Neo
API to generate

235
00:09:55.550 --> 00:09:58.245
an optimized model for
your desired platform,

236
00:09:58.245 --> 00:10:00.650
and you can even deploy and run

237
00:10:00.650 --> 00:10:01.970
that optimized model on

238
00:10:01.970 --> 00:10:05.360
your desired platforms
at no additional charge.

239
00:10:05.360 --> 00:10:07.520
I hope you learn just
a little something

240
00:10:07.520 --> 00:10:09.315
about Amazon SageMaker Neo,

241
00:10:09.315 --> 00:10:12.560
and we'll continue to
explore other AWS videos.

242
00:10:12.560 --> 00:10:15.890
I'm Michelle Metzger with AWS
Training and Certification.

243
00:10:15.890 --> 00:10:18.060
Thank you for watching.