WEBVTT

1
00:00:05.220 --> 00:00:07.915
Hello my name is Arun.

2
00:00:07.915 --> 00:00:10.240
I'm a Senior Technical
Product Manager and I want

3
00:00:10.240 --> 00:00:12.980
to talk with you about
Amazon Comprehend Medical.

4
00:00:12.980 --> 00:00:15.915
So what is Amazon
Comprehend Medical?

5
00:00:15.915 --> 00:00:18.880
Comprehend Medical is a
set of hyper-eligible ML

6
00:00:18.880 --> 00:00:20.935
powered APIs built specifically

7
00:00:20.935 --> 00:00:22.360
for the healthcare domain.

8
00:00:22.360 --> 00:00:25.000
It makes it easy to
extract and structure

9
00:00:25.000 --> 00:00:27.550
information from
unstructured medical text.

10
00:00:27.550 --> 00:00:30.309
It does this with state
of the art accuracy,

11
00:00:30.309 --> 00:00:32.320
helping developers
build applications

12
00:00:32.320 --> 00:00:34.225
that can improve
patient outcomes.

13
00:00:34.225 --> 00:00:37.630
Comprehend Medical makes
advanced medical text analytics

14
00:00:37.630 --> 00:00:41.195
accessible to all developers
with no upfront costs.

15
00:00:41.195 --> 00:00:45.360
What problems exist that
Comprehend Medical can solve?

16
00:00:45.360 --> 00:00:48.220
More than 90 percent of
healthcare providers use

17
00:00:48.220 --> 00:00:51.025
electronic health records
to store a patient data.

18
00:00:51.025 --> 00:00:54.130
Although there are few
structured fields in an EHR,

19
00:00:54.130 --> 00:00:56.710
most of the valuable
patient-care information is

20
00:00:56.710 --> 00:00:59.665
trapped in a free
form clinical text.

21
00:00:59.665 --> 00:01:01.750
An example being admission notes,

22
00:01:01.750 --> 00:01:04.100
patient history, or
discharge notes.

23
00:01:04.100 --> 00:01:07.000
However, extracting value
define insights from

24
00:01:07.000 --> 00:01:08.590
unstructured clinical notes is

25
00:01:08.590 --> 00:01:10.870
a manual and
labor-intensive process,

26
00:01:10.870 --> 00:01:13.600
creating a bottleneck
that slows down analysis

27
00:01:13.600 --> 00:01:16.585
that could result in better
health and business outcomes.

28
00:01:16.585 --> 00:01:18.360
You might be asking, how does

29
00:01:18.360 --> 00:01:20.385
Comprehend Medical actually work?

30
00:01:20.385 --> 00:01:23.140
Well, it is an extension
of Amazon comprehends

31
00:01:23.140 --> 00:01:25.075
natural language
processing models

32
00:01:25.075 --> 00:01:27.740
for entity extraction
of medical texts.

33
00:01:27.740 --> 00:01:30.725
It uses deep learning to
extract entities from

34
00:01:30.725 --> 00:01:32.945
unstructured text in
the healthcare field

35
00:01:32.945 --> 00:01:35.780
such as clinical notes
and radiology readings.

36
00:01:35.780 --> 00:01:37.940
Amazon comprehend leverages the

37
00:01:37.940 --> 00:01:40.190
latest advancements in
machine learning to

38
00:01:40.190 --> 00:01:41.870
bring a high level
of accuracy and

39
00:01:41.870 --> 00:01:44.915
efficiency to extracting
clinical information.

40
00:01:44.915 --> 00:01:47.990
Comprehend Medical
consists of two APIs.

41
00:01:47.990 --> 00:01:50.120
The NERA API, which will

42
00:01:50.120 --> 00:01:53.135
return a JSON with all
the extracted entities,

43
00:01:53.135 --> 00:01:56.240
their traits, and the
relationships between them.

44
00:01:56.240 --> 00:01:59.420
The second API is the
PHId API which will

45
00:01:59.420 --> 00:02:01.460
return just the protected
health information

46
00:02:01.460 --> 00:02:02.855
contained in the text.

47
00:02:02.855 --> 00:02:06.000
Developers can easily integrate
Comprehend Medical into

48
00:02:06.000 --> 00:02:07.585
their data processing pipelines

49
00:02:07.585 --> 00:02:09.665
with tools like Amazon glue.

50
00:02:09.665 --> 00:02:12.710
They can also access it
from SageMaker and extract

51
00:02:12.710 --> 00:02:14.570
structured data to build

52
00:02:14.570 --> 00:02:17.030
accurate models for
health care use cases.

53
00:02:17.030 --> 00:02:19.010
Once the text is extracted,

54
00:02:19.010 --> 00:02:21.095
it can be stored in
services like S3,

55
00:02:21.095 --> 00:02:25.025
Aurora, RDS, and Redshift
or any third party service.

56
00:02:25.025 --> 00:02:26.800
What does this mean for you?

57
00:02:26.800 --> 00:02:29.510
Comprehend Medical can
help improve outcomes.

58
00:02:29.510 --> 00:02:32.210
Identifying a high-risk
patient on time will prevent

59
00:02:32.210 --> 00:02:34.250
further complications
for the patient and

60
00:02:34.250 --> 00:02:36.905
reduce the financial costs
for the health system.

61
00:02:36.905 --> 00:02:38.810
This data is also valuable for

62
00:02:38.810 --> 00:02:41.180
use cases such as clinical
decision support,

63
00:02:41.180 --> 00:02:44.075
revenue cycle management and
clinical trial management

64
00:02:44.075 --> 00:02:45.320
and it's difficult to use

65
00:02:45.320 --> 00:02:47.645
without significant
manual effort.

66
00:02:47.645 --> 00:02:49.910
The ability to
extract and structure

67
00:02:49.910 --> 00:02:52.670
information from unstructured
medical text with

68
00:02:52.670 --> 00:02:54.980
state of the art accuracy
no longer requires

69
00:02:54.980 --> 00:02:57.650
you to be a medical or
machine-learning expert.

70
00:02:57.650 --> 00:03:01.055
Comprehend medical makes
advanced medical text analytics

71
00:03:01.055 --> 00:03:04.625
accessible to all developers
with no upfront costs.

72
00:03:04.625 --> 00:03:07.520
Comprehend Medical's current
performance has been

73
00:03:07.520 --> 00:03:10.570
better than what we have
seen in academic benchmarks.

74
00:03:10.570 --> 00:03:12.260
Well, how about we take a look

75
00:03:12.260 --> 00:03:13.580
at Comprehend Medical right in

76
00:03:13.580 --> 00:03:14.750
the console so you can get

77
00:03:14.750 --> 00:03:17.270
an even better idea
about how it works?

78
00:03:17.270 --> 00:03:19.600
So let's take a look
at Amazon Comprehend

79
00:03:19.600 --> 00:03:20.945
medical's console.

80
00:03:20.945 --> 00:03:23.060
Here we have a de-identified
clinical node,

81
00:03:23.060 --> 00:03:25.470
I'm going to run it
through the service.

82
00:03:26.570 --> 00:03:28.860
So here what we return is

83
00:03:28.860 --> 00:03:31.385
the actual insights from
this analyzed text.

84
00:03:31.385 --> 00:03:33.545
You can see that the color is

85
00:03:33.545 --> 00:03:36.710
specific to a different
entity type that we extract.

86
00:03:36.710 --> 00:03:38.780
Here the orange is

87
00:03:38.780 --> 00:03:41.690
basically for PHI, Protected
Health Information.

88
00:03:41.690 --> 00:03:45.140
Here green is for
medical condition and

89
00:03:45.140 --> 00:03:46.850
we actually have
something called entity

90
00:03:46.850 --> 00:03:49.010
traits that, one is negation.

91
00:03:49.010 --> 00:03:50.060
So if for example,

92
00:03:50.060 --> 00:03:51.860
a patient denies taking
some medication,

93
00:03:51.860 --> 00:03:54.230
that medication would be negated.

94
00:03:54.230 --> 00:03:57.290
Then we show whether a
diagnosis is a sign or symptom.

95
00:03:57.290 --> 00:04:00.140
Why that's important is that
when you work downstream,

96
00:04:00.140 --> 00:04:01.220
it's very important to have

97
00:04:01.220 --> 00:04:03.500
that differentiation
in order to fit

98
00:04:03.500 --> 00:04:05.120
into a lot of workflows that

99
00:04:05.120 --> 00:04:07.435
exist with our health
care customers.

100
00:04:07.435 --> 00:04:10.130
What we also do with
relationship extraction is

101
00:04:10.130 --> 00:04:12.560
we tie the subtypes
to the parents.

102
00:04:12.560 --> 00:04:14.105
So for example here,

103
00:04:14.105 --> 00:04:16.010
the test name is platelet count

104
00:04:16.010 --> 00:04:18.530
and the actual value is
varied significantly.

105
00:04:18.530 --> 00:04:19.790
So you here you can see through

106
00:04:19.790 --> 00:04:22.730
the UI that it is
connected to the parent.

107
00:04:22.730 --> 00:04:24.440
What we've done with this is,

108
00:04:24.440 --> 00:04:27.560
we want to make it really easy
for customers to sift and

109
00:04:27.560 --> 00:04:28.850
sort through this
data not through

110
00:04:28.850 --> 00:04:30.830
simple searches but
more complex ones.

111
00:04:30.830 --> 00:04:32.870
So you can actually search,

112
00:04:32.870 --> 00:04:36.095
for example, medication also
has relationship extraction.

113
00:04:36.095 --> 00:04:38.750
You can search dosages
for medication.

114
00:04:38.750 --> 00:04:41.150
So what we do is, we
tie the medication to

115
00:04:41.150 --> 00:04:44.630
the dosage route or mode,
the strength frequency,

116
00:04:44.630 --> 00:04:46.040
and so you can make
simple searches

117
00:04:46.040 --> 00:04:47.600
about how many of my patients are

118
00:04:47.600 --> 00:04:51.035
taking a certain dosage
of a certain medication.

119
00:04:51.035 --> 00:04:53.270
In the end, we want to
make this easy to use.

120
00:04:53.270 --> 00:04:54.290
We're really trying to distill

121
00:04:54.290 --> 00:04:57.080
a complex process into
a very simple API call.

122
00:04:57.080 --> 00:04:59.660
Moving further, you can
see another example of

123
00:04:59.660 --> 00:05:01.430
relationship
extraction here under

124
00:05:01.430 --> 00:05:03.140
Vital Signs is temperature.

125
00:05:03.140 --> 00:05:05.165
So temperature is the test name

126
00:05:05.165 --> 00:05:07.730
and the value is 36 and
it's connected to it.

127
00:05:07.730 --> 00:05:09.215
So it's very easy for

128
00:05:09.215 --> 00:05:11.390
our customers or for you
to visually look at this

129
00:05:11.390 --> 00:05:15.350
and see how well our ML
powered models are working.

130
00:05:15.350 --> 00:05:17.300
Moving further down
in the console,

131
00:05:17.300 --> 00:05:20.030
you can see like we actually
have a list type or we list

132
00:05:20.030 --> 00:05:21.680
all the entities and
you can actually see

133
00:05:21.680 --> 00:05:24.475
the category and if any
traits are associated.

134
00:05:24.475 --> 00:05:26.630
We also provide the
conference score

135
00:05:26.630 --> 00:05:28.010
so you can see how well

136
00:05:28.010 --> 00:05:29.510
our models are performing on

137
00:05:29.510 --> 00:05:30.620
the unstructured data that

138
00:05:30.620 --> 00:05:32.165
you're running
through the service.

139
00:05:32.165 --> 00:05:34.250
You can also sift and sort

140
00:05:34.250 --> 00:05:36.545
through this data
as you deem fit.

141
00:05:36.545 --> 00:05:38.630
So essentially, if I
wanted to look for

142
00:05:38.630 --> 00:05:40.700
example at test treatment
and procedures,

143
00:05:40.700 --> 00:05:44.330
you can actually see the
platelet count and under it,

144
00:05:44.330 --> 00:05:46.310
what the relationship was with

145
00:05:46.310 --> 00:05:48.620
the subtype and we provide
that here as well.

146
00:05:48.620 --> 00:05:50.045
You can also close it.

147
00:05:50.045 --> 00:05:52.820
So again, we're trying to make
this very easy to use and

148
00:05:52.820 --> 00:05:56.060
very easy for our
customers to sift through.

149
00:05:56.060 --> 00:05:57.770
Honestly, very dense data very,

150
00:05:57.770 --> 00:06:00.215
very difficult to structure data.

151
00:06:00.215 --> 00:06:01.490
These will make it for you,

152
00:06:01.490 --> 00:06:03.470
the better you can
use the service and

153
00:06:03.470 --> 00:06:06.475
obviously scale it for
your specific use cases.

154
00:06:06.475 --> 00:06:09.050
Moving on to the JSON output,
you can see here again,

155
00:06:09.050 --> 00:06:11.000
we make it as easy as
possible and some of

156
00:06:11.000 --> 00:06:14.555
the identifiers that
we have are ID,

157
00:06:14.555 --> 00:06:17.210
the offset like where it's
located in the clinical texts,

158
00:06:17.210 --> 00:06:19.970
the actual score, the text

159
00:06:19.970 --> 00:06:22.820
and the category as I showed
earlier, and the subtypes.

160
00:06:22.820 --> 00:06:25.595
So here the type for
Labahn Hospital,

161
00:06:25.595 --> 00:06:27.755
it's under PHI,

162
00:06:27.755 --> 00:06:30.925
protected health information
and the type is address.

163
00:06:30.925 --> 00:06:35.105
If you move further down you
can see where we actually

164
00:06:35.105 --> 00:06:37.310
nest in the subtypes

165
00:06:37.310 --> 00:06:39.320
when we talk about
relationship extraction.

166
00:06:39.320 --> 00:06:41.880
So now going back to the
example of platelet count,

167
00:06:41.880 --> 00:06:43.910
you can see that
that is a test name.

168
00:06:43.910 --> 00:06:46.205
It's under the category of
test treatment procedure

169
00:06:46.205 --> 00:06:49.145
and the actual value below
it is varied significantly.

170
00:06:49.145 --> 00:06:50.720
So again, when you
take this data out

171
00:06:50.720 --> 00:06:54.660
of Comprehend Medical and
put it into any database,

172
00:06:54.660 --> 00:06:56.760
it could be dynamo,
it could be redshift.

173
00:06:56.760 --> 00:06:57.890
We want to make it

174
00:06:57.890 --> 00:06:59.200
very easy for you to
search through it,

175
00:06:59.200 --> 00:07:01.795
and we believe that this
format allows you to do that.

176
00:07:01.795 --> 00:07:04.580
With that, that's pretty
much what the service does.

177
00:07:04.580 --> 00:07:06.740
We've really tried to take
a very complex process

178
00:07:06.740 --> 00:07:08.555
and make it easy
for our customers.

179
00:07:08.555 --> 00:07:10.340
We believe that if
we can if we can

180
00:07:10.340 --> 00:07:12.120
do a lot of the heavy
lifting and the hard work,

181
00:07:12.120 --> 00:07:14.180
we can actually enhance
our customers to build

182
00:07:14.180 --> 00:07:15.665
all the really cool applications

183
00:07:15.665 --> 00:07:18.575
that can really change
and impact healthcare.

184
00:07:18.575 --> 00:07:21.630
Thanks for learning about
Amazon Comprehend Medical.

185
00:07:21.630 --> 00:07:24.730
On behalf of AWS,
thanks for watching.